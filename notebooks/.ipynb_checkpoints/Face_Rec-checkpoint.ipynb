{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad9cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv2\n",
    "import dlib\n",
    "import face_recognition\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4dda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names():\n",
    "    roots = glob.glob('../data/lfw/train/*')\n",
    "    all_files = [glob.glob(x + '/*') for x in roots]\n",
    "    file_list = [item for sublist in all_files for item in sublist]\n",
    "    return file_list\n",
    "file_list = get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70197c60-91bd-46ec-94c7-641d48e175ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefe796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds face encodings\n",
    "def encodings_names(f_list):\n",
    "    face_encodings = []\n",
    "    names = []\n",
    "    for f in f_list[:]:\n",
    "        name = f.split('/')[4]\n",
    "        image = cv2.imread(f)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        boxes = face_recognition.face_locations(rgb)\n",
    "        if len(boxes) != 0 and len(boxes)<2:\n",
    "            encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "            face_encodings.append(encodings)\n",
    "            names.append(name)\n",
    "    return face_encodings, names\n",
    "face_encodings, names = encodings_names(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09f989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "save_data(names, '../data/processed/lfw_names.pickle')\n",
    "save_data(face_encodings, '../data/processed/lfw_encodings2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e44b4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 512, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def resize_cv2(img, pct):\n",
    "    width = int(img.shape[1] * pct / 100)\n",
    "    height = int(img.shape[0] * pct / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized\n",
    "t_image=cv2.imread('../data/raw/train/eric/MEIMG_17.jpeg')\n",
    "t_image.shape\n",
    "#resized_img = resize_cv2(image, 40)\n",
    "#print(resized_img.shape)\n",
    "#cv2.imwrite('../data/raw/train/eric/MEIMG_17.jpeg', resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34717c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds test encoding\n",
    "f = file_list[10]\n",
    "test_encodings = []\n",
    "name = f.split('/')[-4]\n",
    "image = cv2.imread('../data/raw/train/eric/MEIMG_8.jpeg')\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "boxes = face_recognition.face_locations(rgb)\n",
    "if len(boxes) != 0:\n",
    "    encoding = face_recognition.face_encodings(rgb, boxes)\n",
    "    test_encodings.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd7a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches(known_encodings, unknown_encoding):\n",
    "    threshold = .6\n",
    "    matches = []\n",
    "    for i, k_e in enumerate(known_encodings):\n",
    "        dist = np.linalg.norm(np.array(k_e) - np.array(unknown_encoding[0]), axis = 1)\n",
    "        if dist[0] < threshold:\n",
    "            matches.append(names[i])\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1844bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eric_C', 'Eric_C', 'Eric_C', 'Eric_C', 'Eric_C', 'Eric_C']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_matches = matches(face_encodings, test_encodings)\n",
    "name_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c09cc-ee0d-40fb-bca7-2a83023208a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py_3.9]",
   "language": "python",
   "name": "conda-env-py_3.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
