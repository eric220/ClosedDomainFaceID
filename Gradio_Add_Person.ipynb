{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd0d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericcriteser/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-21 09:01:01.287906: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import pickle\n",
    "import face_recognition\n",
    "from statistics import mode\n",
    "from tqdm import tqdm\n",
    "from py_files import add_new_person as anp\n",
    "import glob\n",
    "from threading import Lock, Thread\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ea05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/processed/lfw_names.pickle', 'rb') as handle:\n",
    "    names = pickle.load(handle)\n",
    "    \n",
    "with open('data/processed/lfw_encodings.pickle', 'rb') as handle:\n",
    "    face_encodings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5067c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_data(t_e, t_n):\n",
    "    for t in t_n:\n",
    "        names.append(t)\n",
    "    for e in t_e:\n",
    "        face_encodings.append(e)\n",
    "    assert len(names) == len(face_encodings)\n",
    "    anp.save_data(names, 'data/processed/lfw_names.pickle')\n",
    "    anp.save_data(face_encodings, 'data/processed/lfw_encodings.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b7abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN FILE LIST 6\n",
      "IMAGE SHAPE (400, 300, 3)\n",
      "BOXES 1\n",
      "IMAGE SHAPE (400, 300, 3)\n",
      "BOXES 1\n",
      "IMAGE SHAPE (400, 300, 3)\n",
      "BOXES 1\n",
      "IMAGE SHAPE (400, 300, 3)\n",
      "BOXES 1\n",
      "IMAGE SHAPE (400, 300, 3)\n",
      "BOXES 1\n",
      "IMAGE SHAPE (400, 300, 3)\n",
      "BOXES 1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def new_person(name, img):\n",
    "    msg = 'Success'\n",
    "    if name != '':\n",
    "        try:\n",
    "            resized_img = anp.resize_img(img)\n",
    "            anp.create_directory(name)\n",
    "            anp.mutate_img(resized_img, name)\n",
    "            file_list = glob.glob('data/processed/temporary_mutated_images/{}/*'.format(name))\n",
    "            t_encodings, t_names = anp.encodings_names(file_list)\n",
    "            _ = save_new_data(t_encodings, t_names)\n",
    "            anp.delete_directory(Path('data/processed/temporary_mutated_images/{}'.format(name))) \n",
    "        except:\n",
    "            msg = 'Failed to process new image'\n",
    "        return msg\n",
    "\n",
    "demo = gr.Interface(fn = new_person, inputs = ['text', 'image'], outputs = 'text')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bfb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
